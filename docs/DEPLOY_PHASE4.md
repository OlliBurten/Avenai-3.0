# Deploy Phase 4 - ChatGPT-Level Intelligence
**Date:** October 23, 2025  
**Status:** Ready for deployment

---

## ðŸš€ Quick Deploy (Copy-Paste)

### **Step 1: Deploy FTS Column (5 min)**

```bash
cd /Users/harburt/Desktop/Avenai\ 3.0

# Add FTS column to database
npm run db:add-fts

# Verify
psql "$DATABASE_URL" -c "SELECT COUNT(*) as total, COUNT(fts) as with_fts FROM document_chunks;"
# Expected: total = with_fts
```

---

### **Step 2: Test FTS Works (2 min)**

```bash
# Test FTS query
psql "$DATABASE_URL" -c "
  SELECT 
    ts_rank_cd(fts, plainto_tsquery('simple', 'authentication')) as rank,
    substring(content, 1, 80) as preview
  FROM document_chunks 
  WHERE fts @@ plainto_tsquery('simple', 'authentication') 
  ORDER BY rank DESC 
  LIMIT 3;
"
```

**Expected:** 3 rows with relevance scores

---

### **Step 3: Run Smoke Tests (10 min)**

```bash
# Set environment
export BASE_URL=http://localhost:3000
export DATASET_ID=eu-test-dataset

# Run smoke tests
npm run eval:smoke
```

**Expected:**
```
âœ… Passed: 15/15 (100%)
ðŸŽ‰ PASS - Meets 95% target!
```

---

### **Step 4: Integration (See Below)**

---

## ðŸ“ Chat API Integration

### **File:** `app/api/chat/route.ts`

**Add these imports:**
```typescript
import { retrieve } from '@/lib/retrieval';
import { createPrompt, postProcess } from '@/lib/generation/promptRouter';
import { extractDocumentLabels } from '@/lib/retrieval/crossDoc';
```

**Replace retrieval section (line ~150-250):**
```typescript
// OLD CODE (remove):
// const chunks = await prisma.documentChunk.findMany({ ... });

// NEW CODE (Phase 4):
console.log(`\n${'='.repeat(60)}`);
console.log(`ðŸš€ [Phase 4] Starting ChatGPT-level retrieval`);
console.log(`${'='.repeat(60)}`);

const retrievalResult = await retrieve({
  query: message,
  datasetId,
  organizationId: (session.user as any).organizationId,
  topK: 12,
  enableFallback: true,
  enableMMR: true,
  enablePolicy: true,
  enableCrossDoc: true,
  enableDomainBoost: true
});

const { results, confidence, metadata } = retrievalResult;

console.log(`\nðŸ“Š [Retrieval] Complete`);
console.log(`   Results: ${results.length}`);
console.log(`   Confidence: ${confidence.level} (${confidence.score.toFixed(2)})`);
console.log(`   Intent: ${metadata.intent}`);
console.log(`   Time: ${metadata.retrievalTimeMs}ms`);
console.log(`   Sources: ${metadata.sourceSummary}`);

// Handle no results
if (results.length === 0) {
  return NextResponse.json({
    message: "I couldn't find relevant information. Could you rephrase?",
    confidence: 'low',
    sources: []
  });
}

// Build contexts with document labels
const contexts = results.map(r => {
  const labels = extractDocumentLabels(r.documentTitle);
  return {
    content: r.content,
    title: r.documentTitle,
    page: r.page,
    sectionPath: r.sectionPath,
    docLabel: labels.label,
    docCountry: labels.country,
    docProduct: labels.product
  };
});

// Generate prompt with strict template
const { system, user } = createPrompt(
  metadata.intent,
  message,
  contexts
);

console.log(`ðŸ’¬ [LLM] Using ${metadata.intent} template`);

// Call LLM (existing code continues...)
const completion = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: system },
    { role: 'user', content: user }
  ],
  temperature: 0.1,
  stream: true
});

// ... (rest of your existing streaming code)
```

---

## ðŸ§ª Testing

### **Local Testing**

```bash
# Start server
npm run dev

# Terminal 2: Run smoke tests
export BASE_URL=http://localhost:3000
export DATASET_ID=eu-test-dataset
npm run eval:smoke

# Terminal 2: Run golden eval
npm run eval:golden
```

### **Production Testing**

```bash
# After deploying to Vercel
export BASE_URL=https://your-app.vercel.app
export DATASET_ID=your-prod-dataset-id
export SESSION_COOKIE="next-auth.session-token=..."

npm run eval:golden
```

---

## ðŸ“Š Expected Results

### **Console Output**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸš€ [Phase 4] Starting ChatGPT-level retrieval
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” [Retrieval Pipeline] Query: "Which authentication headers..."
ðŸŽ¯ [Step 1] Intent: ONE_LINE

ðŸ” [Hybrid Search] Query: "Which authentication headers..."
âš–ï¸ [Hybrid Search] Weights: Vector=0.7, Text=0.3
ðŸŽ¯ [Hybrid Search] Vector: Retrieved 40, top score=0.8542
ðŸ”‘ [Hybrid Search] Text: Retrieved 32, top score=0.4231
ðŸ”€ [Hybrid Search] Fused: 58 unique candidates
âœ… [Hybrid Search] Final: 58 results

ðŸŽ¯ [Policy] Applying ONE_LINE policy to 58 candidates
   âœ… Found 12 preferred candidates for ONE_LINE
ðŸ“ˆ [Domain boost] Applied
ðŸŒ [Cross-Doc] Balanced distribution
ðŸ“Š [MMR] 12 diverse results
âœ… [Confidence] high (0.85) - no fallback needed

ðŸ“Š [Retrieval] Complete
   Results: 12
   Confidence: high (0.85)
   Intent: ONE_LINE
   Time: 95ms
   Sources: BankID Sweden v5 (5), BankID Norway v5.1 (4), Mobile SDK (3)

ðŸ’¬ [LLM] Using ONE_LINE template
```

### **Golden Eval Output**

```
ðŸ“Š GOLDEN EVALUATION REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Passed: 15/15 (100%)
âŒ Failed: 0/15

ðŸ“ˆ Score Breakdown:
   Exact Matches: 96.5%
   Keywords: 98.2%
   Structured: 95.0%

â±ï¸  Performance:
   Avg Duration: 892ms

ðŸ“‚ By Category:
   auth: 3/3 (100%)
   endpoints: 4/4 (100%)
   json: 2/2 (100%)
   errors: 2/2 (100%)
   workflows: 2/2 (100%)
   sdk: 2/2 (100%)

ðŸŽ¯ By Intent:
   ONE_LINE: 4/4 (100%)
   ENDPOINT: 4/4 (100%)
   JSON: 2/2 (100%)
   ERROR_CODE: 2/2 (100%)
   WORKFLOW: 3/3 (100%)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸŽ‰ PASS - Meets 95% target!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ðŸŽ¯ Rollback Plan

If issues arise:

```bash
# Disable Phase 4 features
echo "HYBRID_RETRIEVAL=false" >> .env.local
echo "CONFIDENCE_FALLBACK=false" >> .env.local
echo "PROMPT_ROUTER_V2=false" >> .env.local

# Restart
npm run dev

# Rollback FTS (only if causing issues)
psql "$DATABASE_URL" -c "
  ALTER TABLE document_chunks DROP COLUMN IF EXISTS fts;
  DROP INDEX IF EXISTS idx_chunks_fts;
"
```

---

## ðŸ“‹ Deployment Checklist

- [ ] FTS column deployed (`npm run db:add-fts`)
- [ ] FTS verified (test query returns results)
- [ ] Code integrated (retrieval + prompt router)
- [ ] Local smoke tests passed
- [ ] Golden eval passed (â‰¥95%)
- [ ] Production deployed (Vercel)
- [ ] Production tests passed
- [ ] Monitoring enabled (SLOs)

---

## ðŸŽ‰ Success Criteria

### **Quality**
- âœ… â‰¥95% pass rate
- âœ… No "refer to docs"
- âœ… Copy-ready code blocks
- âœ… Proper markdown formatting

### **Performance**
- âœ… Retrieval <120ms p95
- âœ… Total latency <1.8s p95
- âœ… Memory <50MB/request

### **User Experience**
- âœ… Answers match ChatGPT quality
- âœ… Source chips labeled by doc/country
- âœ… Confidence always accurate
- âœ… Beautiful formatting (Shiki)

---

**ðŸš€ Ready to deploy? Run: `npm run db:add-fts`**

---

**Maintained by:** Avenai Development Team  
**Last Updated:** October 23, 2025

